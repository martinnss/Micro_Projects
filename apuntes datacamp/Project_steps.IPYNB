{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasos de un proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* importar paquetes y datos\n",
    "* data.head data.columns, shape, dtypes, data.describe()\n",
    "* verificar valores NaN  o missing \n",
    "    * dropna(axis=1,thresh=3)      #borra todas las columnas que tengan desde 3 valores na \n",
    "    * isnull() data.drop()\n",
    "    * data[data['col1'].notnull()] \n",
    "    * data[data['xd']==78]]\n",
    "* Convert dtypes   #entender bien el dataset para saber que tipos de datos debemos usar\n",
    "    * df['col1']=df['col1'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* eliminar columnas irrelevamtes \n",
    "    * Usar t-SNE para visualizar high dimensional data\n",
    "        * Antes se deben selecionar solo las columnas numericas y dejar un dataset df_numeric\n",
    "        * learning_rate=np.arange(10,10000,10) * ejemplo\n",
    "        * agregar al dataset original las dos columnas resultantes df[x], df[y]\n",
    "        * visualizar las columnas resulantes en un scatterplot con hue=categorical_columns\n",
    "    * buscar las columnas con menor varianza y eliminarlas usando VarianceThreshold (apunte dimensionalyty reduction datacmp)\n",
    "* EDA\n",
    "    * \n",
    "* Feature extraction\n",
    "    * Scale data(fit transform, standard sclaer, log normalziation)\n",
    "\n",
    "* Feature Engineering (preprocessing apunte)\n",
    "    * Binary enconding\n",
    "    * one-hot encoder (pd.get_dummies())\n",
    "\n",
    "* feature selection:\n",
    "    * pairplot\n",
    "    * buscar las columnas con menor varianza y eliminarlas usando VarianceThreshold (apunte dimensionalyty reduction datacmp)\n",
    "    * Redundant features (preprocessing apunte)\n",
    "        * noisy, correlated and duplicated features. Usando una mask y corr()\n",
    "        * Identify a column where the correlation value is higher between several features and store it in the to_drop variable.\n",
    "* PCA (last step) (dimensionality reduction apunte)\n",
    "    * Fit PCA and study their components (en casod e tener muchas features)\n",
    "    * Tansfromed_X to train_test_split(X_transformed,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* X_train, X_test,y_train, y_test = train_test_split(X,y, stratify=y)\n",
    "    * PCA\n",
    "* Fit the model\n",
    "* analyze the metrics\n",
    "    * If accuracy_score(ytest,model.predict(Xtest)) << accuracy_score(ytrain,model.predict(Xtrain)) EXISTE OVERFITTING\n",
    "    para disminuir el efecto del overfitting debemos buscar solamente las columnas mas representativas del dataset \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
