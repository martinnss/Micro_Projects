{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# XGBOOST\r\n",
    "\r\n",
    "* XGBoost metrics and crossvalidation\r\n",
    "* XGBoost regressor\r\n",
    "    * Linear base learner\r\n",
    "    * Decision trees as base learner\r\n",
    "    * Regularizations\r\n",
    "* Hyperparameter tunning\r\n",
    "    * GridSearch and RandomizedSearch\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    \r\n",
    "* Project\r\n",
    "    * XGBoost in pipelines\r\n",
    "* Project 2\r\n",
    "    * XGBoost tuning hyperparameters in pipeline (regression)\r\n",
    "* Project 3\r\n",
    "    * Pipeline encoding with numerical and string values\r\n",
    "    * PROYECTO CON ERROR "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost uses decision trees to perform the predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Import the necessary modules\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.tree import DecisionTreeClassifier \r\n",
    "from sklearn.datasets import load_breast_cancer\r\n",
    "data = load_breast_cancer()\r\n",
    "X,y=data.data, data.target\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# Create the training and test sets\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=123)\r\n",
    "\r\n",
    "# Instantiate the classifier: dt_clf_4\r\n",
    "dt_clf_4 = DecisionTreeClassifier(max_depth=4)\r\n",
    "                     #max_depth:pecifies the maximum number of successive split points you can have before reaching a leaf node\r\n",
    "\r\n",
    "# Fit the classifier to the training set\r\n",
    "dt_clf_4.fit(X_train,y_train)\r\n",
    "\r\n",
    "# Predict the labels of the test set: y_pred_4\r\n",
    "y_pred_4 = dt_clf_4.predict(X_test)\r\n",
    "\r\n",
    "# Compute the accuracy of the predictions: accuracy\r\n",
    "accuracy = float(np.sum(y_pred_4==y_test))/y_test.shape[0]\r\n",
    "print(\"accuracy:\", accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using XGBoost and Cross validation with errror metric"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import xgboost as xgb\r\n",
    "\r\n",
    "# Create the DMatrix from X and y: churn_dmatrix\r\n",
    "churn_dmatrix = xgb.DMatrix(data=X, label=y)\r\n",
    "\r\n",
    "# Create the parameter dictionary: params\r\n",
    "params = {\"objective\":\"binary:logistic\", \"max_depth\":3}\r\n",
    "\r\n",
    "# Perform cross-validation: cv_results\r\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, \r\n",
    "                  nfold=100, num_boost_round=100, \r\n",
    "                  metrics=\"error\", as_pandas=True, seed=123)\r\n",
    "\r\n",
    "# Print cv_results\r\n",
    "print(cv_results)\r\n",
    "\r\n",
    "# Print the accuracy\r\n",
    "print(((1-cv_results[\"test-error-mean\"]).iloc[-1]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    train-error-mean  train-error-std  test-error-mean  test-error-std\n",
      "0           0.026167         0.003495         0.093333        0.123288\n",
      "1           0.017255         0.003301         0.064667        0.097162\n",
      "2           0.015675         0.001979         0.062667        0.096411\n",
      "3           0.012923         0.002258         0.056333        0.092219\n",
      "4           0.011450         0.002089         0.052333        0.087083\n",
      "..               ...              ...              ...             ...\n",
      "95          0.000000         0.000000         0.029333        0.073224\n",
      "96          0.000000         0.000000         0.029333        0.073224\n",
      "97          0.000000         0.000000         0.029333        0.073224\n",
      "98          0.000000         0.000000         0.029333        0.073224\n",
      "99          0.000000         0.000000         0.029333        0.073224\n",
      "\n",
      "[100 rows x 4 columns]\n",
      "0.97066664\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Perform cross_validation: cv_results\r\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, \r\n",
    "                  nfold=100, num_boost_round=100, \r\n",
    "                  metrics=\"auc\", as_pandas=True, seed=123)\r\n",
    "\r\n",
    "# Print cv_results\r\n",
    "print(cv_results)\r\n",
    "\r\n",
    "# Print the AUC\r\n",
    "print((cv_results[\"test-auc-mean\"]).iloc[-1])\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#hay un error con la metrica AUC"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[11:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/metric/auc.cc:307: Dataset contains only positive or negative samples.\n",
      "    train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0         0.989465       0.002127            NaN           NaN\n",
      "1         0.993539       0.001438            NaN           NaN\n",
      "2         0.995363       0.001379            NaN           NaN\n",
      "3         0.996199       0.001064            NaN           NaN\n",
      "4         0.997472       0.000850            NaN           NaN\n",
      "..             ...            ...            ...           ...\n",
      "95        1.000000       0.000000            NaN           NaN\n",
      "96        1.000000       0.000000            NaN           NaN\n",
      "97        1.000000       0.000000            NaN           NaN\n",
      "98        1.000000       0.000000            NaN           NaN\n",
      "99        1.000000       0.000000            NaN           NaN\n",
      "\n",
      "[100 rows x 4 columns]\n",
      "nan\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XGB regressor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import mean_squared_error, r2_score\r\n",
    "\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "boston=pd.read_csv('HousingData.csv')\r\n",
    "y=boston['MEDV']\r\n",
    "X= boston.drop('MEDV', axis = 1)\r\n",
    "print(boston)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
      "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
      "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
      "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
      "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
      "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
      "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
      "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
      "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
      "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
      "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
      "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
      "\n",
      "     PTRATIO       B  LSTAT  MEDV  \n",
      "0       15.3  396.90   4.98  24.0  \n",
      "1       17.8  396.90   9.14  21.6  \n",
      "2       17.8  392.83   4.03  34.7  \n",
      "3       18.7  394.63   2.94  33.4  \n",
      "4       18.7  396.90    NaN  36.2  \n",
      "..       ...     ...    ...   ...  \n",
      "501     21.0  391.99    NaN  22.4  \n",
      "502     21.0  396.90   9.08  20.6  \n",
      "503     21.0  396.90   5.64  23.9  \n",
      "504     21.0  393.45   6.48  22.0  \n",
      "505     21.0  396.90   7.88  11.9  \n",
      "\n",
      "[506 rows x 14 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tree as base learner"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Create the training and test sets\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=123)\r\n",
    "\r\n",
    "# Instantiate the XGBRegressor: xg_reg\r\n",
    "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=10,booster='gbtree',seed=123)\r\n",
    "\r\n",
    "# Fit the regressor to the training set\r\n",
    "xg_reg.fit(X_train,y_train)\r\n",
    "\r\n",
    "# Predict the labels of the test set: preds\r\n",
    "preds = xg_reg.predict(X_test)\r\n",
    "\r\n",
    "# Compute the rmse: rmse\r\n",
    "rmse = np.sqrt(mean_squared_error(y_test,preds))\r\n",
    "print(\"RMSE: %f\" % (rmse))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE: 4.560782\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear base learner\r\n",
    "This model, although not as commonly used in XGBoost, allows you to create a regularized linear regression using XGBoost's powerful learning API."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Convert the training and testing sets into DMatrixes: DM_train, DM_test\r\n",
    "DM_train = xgb.DMatrix(data=X_train,label=y_train)\r\n",
    "DM_test =  xgb.DMatrix(data=X_test,label=y_test)\r\n",
    "\r\n",
    "# Create the parameter dictionary: params\r\n",
    "params = {\"booster\":\"gblinear\", \"objective\":'reg:squarederror'}\r\n",
    "\r\n",
    "# Train the model: xg_reg\r\n",
    "xg_reg = xgb.train(params=params, dtrain=DM_train, num_boost_round=5)\r\n",
    "\r\n",
    "# Predict the labels of the test set: preds\r\n",
    "preds = xg_reg.predict(DM_test)\r\n",
    "\r\n",
    "# Compute and print the RMSE\r\n",
    "rmse = np.sqrt(mean_squared_error(y_test,preds))\r\n",
    "print(\"RMSE: %f\" % (rmse))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE: 7.378787\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Im this case, the tree based model perfomed better thnat the linear base learner"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evuating the RMSE and MAE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Create the DMatrix: housing_dmatrix\r\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\r\n",
    "\r\n",
    "# Create the parameter dictionary: params\r\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\r\n",
    "\r\n",
    "# Perform cross-validation: cv_results\r\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=4, num_boost_round=5, metrics='rmse', as_pandas=True, seed=123)\r\n",
    "\r\n",
    "# Print cv_results\r\n",
    "print(cv_results)\r\n",
    "\r\n",
    "# Extract and print final boosting round metric\r\n",
    "print((cv_results[\"test-rmse-mean\"]).tail(1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[11:21:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
      "0        17.119575        0.061488       17.081123       0.279813\n",
      "1        12.369863        0.039201       12.415917       0.309028\n",
      "2         9.047235        0.042909        9.314515       0.342472\n",
      "3         6.733032        0.027643        7.152707       0.387316\n",
      "4         5.129891        0.025044        5.805512       0.344630\n",
      "4    5.805512\n",
      "Name: test-rmse-mean, dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Create the DMatrix: housing_dmatrix\r\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\r\n",
    "\r\n",
    "# Create the parameter dictionary: params\r\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\r\n",
    "\r\n",
    "# Perform cross-validation: cv_results\r\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=4, num_boost_round=5, metrics='mae', as_pandas=True, seed=123)\r\n",
    "\r\n",
    "# Print cv_results\r\n",
    "print(cv_results)\r\n",
    "\r\n",
    "# Extract and print final boosting round metric\r\n",
    "print((cv_results[\"test-mae-mean\"]).tail(1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[11:21:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "   train-mae-mean  train-mae-std  test-mae-mean  test-mae-std\n",
      "0       15.580292       0.087856      15.500486      0.334724\n",
      "1       11.033787       0.067857      10.965437      0.295594\n",
      "2        7.841826       0.047672       7.890744      0.297810\n",
      "3        5.625617       0.045695       5.728912      0.269153\n",
      "4        4.113999       0.034062       4.400558      0.205865\n",
      "4    4.400558\n",
      "Name: test-mae-mean, dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regularizations\r\n",
    "Vary the l2 regularization penalty - also known as \"lambda\" - and see its effect on overall model performance on the housing dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Create the DMatrix: housing_dmatrix\r\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\r\n",
    "\r\n",
    "reg_params = [1, 10, 100]\r\n",
    "\r\n",
    "# Create the initial parameter dictionary for varying l2 strength: params\r\n",
    "params = {\"objective\":\"reg:squarederror\",\"max_depth\":3}\r\n",
    "\r\n",
    "# Create an empty list for storing rmses as a function of l2 complexity\r\n",
    "rmses_l2 = []\r\n",
    "\r\n",
    "# Iterate over reg_params\r\n",
    "for reg in reg_params:\r\n",
    "\r\n",
    "    # Update l2 strength\r\n",
    "    params[\"lambda\"] = reg\r\n",
    "    \r\n",
    "    # Pass this updated param dictionary into cv\r\n",
    "    cv_results_rmse = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2, num_boost_round=5, metrics=\"rmse\", as_pandas=True, seed=123)\r\n",
    "    \r\n",
    "    # Append best rmse (final round) to rmses_l2\r\n",
    "    rmses_l2.append(cv_results_rmse[\"test-rmse-mean\"].tail(1).values[0])\r\n",
    "\r\n",
    "# Look at best rmse per l2 param\r\n",
    "print(\"Best rmse as a function of l2:\")\r\n",
    "print(pd.DataFrame(list(zip(reg_params, rmses_l2)), columns=[\"l2\", \"rmse\"]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best rmse as a function of l2:\n",
      "    l2       rmse\n",
      "0    1   6.093842\n",
      "1   10   7.272356\n",
      "2  100  10.708530\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualizing individual XGBoost trees\r\n",
    "\r\n",
    "\r\n",
    "Now that you've used XGBoost to both build and evaluate regression as well as classification models, you should get a handle on how to visually explore your models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Create the DMatrix: housing_dmatrix\r\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\r\n",
    "\r\n",
    "# Create the parameter dictionary: params\r\n",
    "params = {\"objective\":\"reg:squarederror\", \"max_depth\":2}\r\n",
    "\r\n",
    "# Train the model: xg_reg\r\n",
    "xg_reg = xgb.train(params=params, dtrain=housing_dmatrix, num_boost_round=10)\r\n",
    "\r\n",
    "# Plot the first tree\r\n",
    "#xgb.plot_tree(xg_reg, num_trees=0)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# Plot the fifth tree\r\n",
    "#xgb.plot_tree(xg_reg, num_trees=4)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# Plot the last tree sideways\r\n",
    "#xgb.plot_tree(xg_reg, num_trees=9, rankdir='LR')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Create the DMatrix: housing_dmatrix\r\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\r\n",
    "\r\n",
    "# Create the parameter dictionary: params\r\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\r\n",
    "\r\n",
    "# Train the model: xg_reg\r\n",
    "xg_reg = xgb.train(params=params, dtrain=housing_dmatrix, num_boost_round=10)\r\n",
    "\r\n",
    "\r\n",
    "# Plot the feature importances\r\n",
    "xgb.plot_importance(xg_reg)\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[11:21:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter tunning\r\n",
    "\r\n",
    "Early stopping works by testing the XGBoost model after every boosting round against a hold-out dataset and stopping the creation of additional boosting rounds (thereby finishing training of the model early) if the hold-out metric (\"rmse\" in our case) does not improve for a given number of rounds."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Create your housing DMatrix: housing_dmatrix\r\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\r\n",
    "\r\n",
    "# Create the parameter dictionary for each tree: params\r\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\r\n",
    "\r\n",
    "# Perform cross-validation with early stopping: cv_results\r\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3,num_boost_round=50, early_stopping_rounds=10, metrics=\"rmse\", as_pandas=True, seed=123)\r\n",
    "    \r\n",
    "print(cv_results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[11:21:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
      "0         17.135521        0.015378       17.243947       0.137534\n",
      "1         12.395737        0.012655       12.631060       0.155951\n",
      "2          9.058271        0.034856        9.531997       0.108915\n",
      "3          6.731977        0.050528        7.397624       0.171025\n",
      "4          5.112203        0.043497        5.977827       0.250369\n",
      "5          3.996804        0.054975        5.153222       0.306803\n",
      "6          3.241921        0.054004        4.580999       0.395096\n",
      "7          2.725877        0.041996        4.251925       0.444447\n",
      "8          2.370989        0.031505        4.019481       0.468605\n",
      "9          2.117409        0.032986        3.881623       0.501792\n",
      "10         1.935882        0.032310        3.773810       0.502332\n",
      "11         1.794742        0.025878        3.729088       0.529758\n",
      "12         1.681319        0.033143        3.674584       0.547770\n",
      "13         1.593310        0.047289        3.624096       0.559366\n",
      "14         1.524358        0.042993        3.593539       0.570888\n",
      "15         1.464844        0.051239        3.557945       0.562816\n",
      "16         1.408468        0.058285        3.531328       0.563070\n",
      "17         1.349848        0.067393        3.530561       0.575859\n",
      "18         1.296485        0.045235        3.517674       0.565959\n",
      "19         1.252304        0.052574        3.516424       0.572733\n",
      "20         1.216591        0.061878        3.519600       0.575530\n",
      "21         1.166831        0.044497        3.513298       0.567750\n",
      "22         1.122064        0.048665        3.507605       0.567082\n",
      "23         1.091034        0.049979        3.499431       0.572795\n",
      "24         1.060936        0.055937        3.494564       0.576073\n",
      "25         1.039437        0.055878        3.490943       0.574712\n",
      "26         1.001401        0.059251        3.494240       0.587041\n",
      "27         0.978549        0.060524        3.490802       0.589866\n",
      "28         0.943546        0.052384        3.483027       0.596942\n",
      "29         0.925038        0.047967        3.483913       0.599816\n",
      "30         0.892548        0.042694        3.482071       0.599047\n",
      "31         0.867546        0.044415        3.479414       0.589477\n",
      "32         0.850339        0.041062        3.474838       0.598479\n",
      "33         0.823323        0.043293        3.470383       0.604505\n",
      "34         0.794769        0.039883        3.470972       0.605365\n",
      "35         0.769107        0.034163        3.467929       0.606238\n",
      "36         0.744624        0.031810        3.463696       0.611075\n",
      "37         0.723200        0.035972        3.466162       0.609110\n",
      "38         0.701027        0.043140        3.468712       0.615487\n",
      "39         0.675442        0.042767        3.459355       0.613845\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## It's time to practice tuning other XGBoost hyperparameters in earnest and observing their effect on model performance! You'll begin by tuning the \"eta\", also known as the learning rate."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Create your housing DMatrix: housing_dmatrix\r\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\r\n",
    "\r\n",
    "# Create the parameter dictionary for each tree (boosting round)\r\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":3}\r\n",
    "\r\n",
    "# Create list of eta values and empty list to store final round rmse per xgboost model\r\n",
    "eta_vals= [0.001,0.01,0.1]\r\n",
    "best_rmse = []\r\n",
    "\r\n",
    "# Systematically vary the eta \r\n",
    "for curr_val in eta_vals:\r\n",
    "\r\n",
    "    params[\"eta\"] = curr_val\r\n",
    "    \r\n",
    "    # Perform cross-validation: cv_results\r\n",
    "    cv_results = xgb.cv(nfold=3, num_boost_round=10, early_stopping_rounds=5,metrics='rmse',seed=123, as_pandas=True,dtrain=housing_dmatrix,params=params)\r\n",
    "    \r\n",
    "    \r\n",
    "    \r\n",
    "    # Append the final round rmse to best_rmse\r\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\r\n",
    "\r\n",
    "# Print the resultant DataFrame\r\n",
    "print(pd.DataFrame(list(zip(eta_vals, best_rmse)), columns=[\"eta\",\"best_rmse\"]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "     eta  best_rmse\n",
      "0  0.001  23.649307\n",
      "1  0.010  21.734927\n",
      "2  0.100   9.593952\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Create your housing DMatrix: housing_dmatrix\r\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\r\n",
    "\r\n",
    "# Create the parameter dictionary\r\n",
    "params = {\"objective\":\"reg:linear\"}\r\n",
    "\r\n",
    "# Create list of max_depth values\r\n",
    "max_depths = [2, 5, 10, 20]\r\n",
    "best_rmse = []\r\n",
    "\r\n",
    "# Systematically vary the max_depth\r\n",
    "for curr_val in max_depths:\r\n",
    "\r\n",
    "    params[\"max_depth\"] = curr_val\r\n",
    "    \r\n",
    "    # Perform cross-validation\r\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,\r\n",
    "                 num_boost_round=10, early_stopping_rounds=5,\r\n",
    "                 metrics=\"rmse\", as_pandas=True, seed=123)\r\n",
    "    \r\n",
    "    # Append the final round rmse to best_rmse\r\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\r\n",
    "\r\n",
    "# Print the resultant DataFrame\r\n",
    "print(pd.DataFrame(list(zip(max_depths, best_rmse)),columns=[\"max_depth\",\"best_rmse\"]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "   max_depth  best_rmse\n",
      "0          2   4.272515\n",
      "1          5   4.101985\n",
      "2         10   3.977780\n",
      "3         20   3.995788\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Create your housing DMatrix\r\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\r\n",
    "\r\n",
    "# Create the parameter dictionary\r\n",
    "params={\"objective\":\"reg:linear\",\"max_depth\":3}\r\n",
    "\r\n",
    "# Create list of hyperparameter values: colsample_bytree_vals\r\n",
    "colsample_bytree_vals=[0.1,0.5,0.8,1]\r\n",
    "best_rmse = []\r\n",
    "\r\n",
    "# Systematically vary the hyperparameter value \r\n",
    "for curr_val in colsample_bytree_vals:\r\n",
    "\r\n",
    "    params['colsample_bytree']=curr_val\r\n",
    "    \r\n",
    "    # Perform cross-validation\r\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,\r\n",
    "                 num_boost_round=10, early_stopping_rounds=5,\r\n",
    "                 metrics=\"rmse\", as_pandas=True, seed=123)\r\n",
    "    \r\n",
    "    # Append the final round rmse to best_rmse\r\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\r\n",
    "\r\n",
    "# Print the resultant DataFrame\r\n",
    "print(pd.DataFrame(list(zip(colsample_bytree_vals, best_rmse)), columns=[\"colsample_bytree\",\"best_rmse\"]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "   colsample_bytree  best_rmse\n",
      "0               0.1   6.191510\n",
      "1               0.5   4.064273\n",
      "2               0.8   3.999197\n",
      "3               1.0   4.167813\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GridSearchCV and RandomizedSearchCV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\r\n",
    "# Create the parameter grid: gbm_param_grid\r\n",
    "gbm_param_grid = {\r\n",
    "    'colsample_bytree': [0.3,0.7],\r\n",
    "    'n_estimators': [50],\r\n",
    "    'max_depth': [2,5]\r\n",
    "}\r\n",
    "\r\n",
    "# Instantiate the regressor: gbm\r\n",
    "gbm = xgb.XGBRegressor()\r\n",
    "\r\n",
    "# Perform grid search: grid_mse\r\n",
    "grid_mse = GridSearchCV(estimator=gbm,param_grid=gbm_param_grid,scoring='neg_mean_squared_error',cv=4,verbose=1)\r\n",
    "\r\n",
    "\r\n",
    "# Fit grid_mse to the data\r\n",
    "grid_mse.fit(X,y)\r\n",
    "\r\n",
    "# Print the best parameters and lowest RMSE\r\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\r\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Best parameters found:  {'colsample_bytree': 0.7, 'max_depth': 2, 'n_estimators': 50}\n",
      "Lowest RMSE found:  4.666172319795653\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Create the parameter grid: gbm_param_grid \r\n",
    "gbm_param_grid = {\r\n",
    "    'n_estimators': [25],\r\n",
    "    'max_depth': range(2,12)\r\n",
    "}\r\n",
    "\r\n",
    "# Instantiate the regressor: gbm\r\n",
    "gbm = xgb.XGBRegressor(n_estimators=10)\r\n",
    "\r\n",
    "# Perform random search: grid_mse\r\n",
    "randomized_mse = RandomizedSearchCV(estimator=gbm,param_distributions=gbm_param_grid,n_iter=5,scoring='neg_mean_squared_error',cv=4,verbose=1)\r\n",
    "\r\n",
    "# Fit randomized_mse to the data\r\n",
    "randomized_mse.fit(X,y)\r\n",
    "\r\n",
    "# Print the best parameters and lowest RMSE\r\n",
    "print(\"Best parameters found: \", randomized_mse.best_params_)\r\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(randomized_mse.best_score_)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Best parameters found:  {'n_estimators': 25, 'max_depth': 4}\n",
      "Lowest RMSE found:  4.597775984022396\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Project\r\n",
    "1. preprocessing: The data has five categorical columns: MSZoning, PavedDrive, Neighborhood, BldgType, and HouseStyle. Scikit-learn has a LabelEncoder function that converts the values in each categorical column into integers. You'll practice using this here."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "df=pd.read_csv('https://assets.datacamp.com/production/repositories/943/datasets/17a7c5c0acd7bfa253827ea53646cf0db7d39649/ames_unprocessed_data.csv')\r\n",
    "# Import LabelEncoder\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "\r\n",
    "# Fill missing values with 0\r\n",
    "df.LotFrontage = df.LotFrontage.fillna(0)\r\n",
    "\r\n",
    "# Create a boolean mask for categorical columns\r\n",
    "categorical_mask = (df.dtypes == object)\r\n",
    "\r\n",
    "# Get list of categorical column names\r\n",
    "categorical_columns = df.columns[categorical_mask].tolist()\r\n",
    "\r\n",
    "# Print the head of the categorical columns\r\n",
    "#print(df[categorical_columns].head())\r\n",
    "\r\n",
    "# Create LabelEncoder object: le\r\n",
    "le = LabelEncoder()\r\n",
    "\r\n",
    "# Apply LabelEncoder to categorical columns\r\n",
    "df[categorical_columns] = df[categorical_columns].apply(lambda x: le.fit_transform(x))\r\n",
    "\r\n",
    "# Print the head of the LabelEncoded categorical columns\r\n",
    "print(df[categorical_columns].head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   MSZoning  Neighborhood  BldgType  HouseStyle  PavedDrive\n",
      "0         3             5         0           5           2\n",
      "1         3            24         0           2           2\n",
      "2         3             5         0           5           2\n",
      "3         3             6         0           5           2\n",
      "4         3            15         0           5           2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " Using LabelEncoder, the CollgCr Neighborhood was encoded as 5, while the Veenker Neighborhood was encoded as 24, and Crawfor as 6. Is Veenker \"greater\" than Crawfor and CollgCr? No - and allowing the model to assume this natural ordering may result in poor performance.\r\n",
    "\r\n",
    "As a result, there is another step needed: You have to apply a one-hot encoding to create binary, or \"dummy\" variables. You can do this using scikit-learn's OneHotEncoder."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "y=df.SalePrice\r\n",
    "X=df.drop(columns=['SalePrice'])\r\n",
    "print(X)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      MSSubClass  MSZoning  LotFrontage  LotArea  Neighborhood  BldgType  \\\n",
      "0             60         3         65.0     8450             5         0   \n",
      "1             20         3         80.0     9600            24         0   \n",
      "2             60         3         68.0    11250             5         0   \n",
      "3             70         3         60.0     9550             6         0   \n",
      "4             60         3         84.0    14260            15         0   \n",
      "...          ...       ...          ...      ...           ...       ...   \n",
      "1455          60         3         62.0     7917             8         0   \n",
      "1456          20         3         85.0    13175            14         0   \n",
      "1457          70         3         66.0     9042             6         0   \n",
      "1458          20         3         68.0     9717            12         0   \n",
      "1459          20         3         75.0     9937             7         0   \n",
      "\n",
      "      HouseStyle  OverallQual  OverallCond  YearBuilt  Remodeled  GrLivArea  \\\n",
      "0              5            7            5       2003          0       1710   \n",
      "1              2            6            8       1976          0       1262   \n",
      "2              5            7            5       2001          1       1786   \n",
      "3              5            7            5       1915          1       1717   \n",
      "4              5            8            5       2000          0       2198   \n",
      "...          ...          ...          ...        ...        ...        ...   \n",
      "1455           5            6            5       1999          1       1647   \n",
      "1456           2            6            6       1978          1       2073   \n",
      "1457           5            7            9       1941          1       2340   \n",
      "1458           2            5            6       1950          1       1078   \n",
      "1459           2            5            6       1965          0       1256   \n",
      "\n",
      "      BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
      "0                1             0         2         1             3   \n",
      "1                0             1         2         0             3   \n",
      "2                1             0         2         1             3   \n",
      "3                1             0         1         0             3   \n",
      "4                1             0         2         1             4   \n",
      "...            ...           ...       ...       ...           ...   \n",
      "1455             0             0         2         1             3   \n",
      "1456             1             0         2         0             3   \n",
      "1457             0             0         2         0             4   \n",
      "1458             1             0         1         0             2   \n",
      "1459             1             0         1         1             3   \n",
      "\n",
      "      Fireplaces  GarageArea  PavedDrive  \n",
      "0              0         548           2  \n",
      "1              1         460           2  \n",
      "2              1         608           2  \n",
      "3              1         642           2  \n",
      "4              1         836           2  \n",
      "...          ...         ...         ...  \n",
      "1455           1         460           2  \n",
      "1456           2         500           2  \n",
      "1457           2         252           2  \n",
      "1458           0         240           2  \n",
      "1459           0         276           2  \n",
      "\n",
      "[1460 rows x 20 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Import necessary modules\r\n",
    "from sklearn.feature_extraction import DictVectorizer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "\r\n",
    "# Fill LotFrontage missing values with 0\r\n",
    "X.LotFrontage = X.LotFrontage.fillna(0)\r\n",
    "\r\n",
    "# Setup the pipeline steps: steps\r\n",
    "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\r\n",
    "         (\"xgb_model\", xgb.XGBRegressor())]\r\n",
    "\r\n",
    "# Create the pipeline: xgb_pipeline\r\n",
    "xgb_pipeline = Pipeline(steps)\r\n",
    "\r\n",
    "# Fit the pipeline\r\n",
    "xgb_pipeline.fit(X.to_dict(\"records\"), y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ohe_onestep', DictVectorizer(sparse=False)),\n",
       "                ('xgb_model',\n",
       "                 XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                              colsample_bylevel=1, colsample_bynode=1,\n",
       "                              colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                              importance_type='gain',\n",
       "                              interaction_constraints='',\n",
       "                              learning_rate=0.300000012, max_delta_step=0,\n",
       "                              max_depth=6, min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints='()', n_estimators=100,\n",
       "                              n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                              subsample=1, tree_method='exact',\n",
       "                              validate_parameters=1, verbosity=None))])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this exercise, you'll go one step further by using the pipeline you've created to preprocess and cross-validate your model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Import necessary modules\r\n",
    "from sklearn.feature_extraction import DictVectorizer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "\r\n",
    "# Fill LotFrontage missing values with 0\r\n",
    "X.LotFrontage = X.LotFrontage.fillna(0)\r\n",
    "\r\n",
    "# Setup the pipeline steps: steps\r\n",
    "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\r\n",
    "         (\"xgb_model\", xgb.XGBRegressor(max_depth=2, objective=\"reg:linear\"))]\r\n",
    "\r\n",
    "# Create the pipeline: xgb_pipeline\r\n",
    "xgb_pipeline = Pipeline(steps)\r\n",
    "\r\n",
    "# Cross-validate the model\r\n",
    "cross_val_scores = cross_val_score(xgb_pipeline,X.to_dict('records'),y,scoring='neg_mean_squared_error',cv=10)\r\n",
    "\r\n",
    "# Print the 10-fold RMSE\r\n",
    "print(\"10-fold RMSE: \", np.mean(np.sqrt(np.abs(cross_val_scores))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[11:21:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "10-fold RMSE:  27808.870767824585\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Proyect 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "boston=pd.read_csv('HousingData.csv')\r\n",
    "y=boston['MEDV']\r\n",
    "X= boston.drop('MEDV', axis = 1)\r\n",
    "print(boston)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from xgboost import XGBRegressor\r\n",
    "pipeline=Pipeline[('st_scaler',StandardScaler()),('xgb_model',XGBRegressor())]\r\n",
    "param_grid={\r\n",
    "    'xgb_model__subsample': np.arange(.05, 1, .05),\r\n",
    "    'xgb_model__max_depth': np.arange(3,20,1),\r\n",
    "    'xgb_model__colsample_bytree': np.arange(.1,1.05,.05)}\r\n",
    "rand_search=RandomizedSearchCV(estimator=pipeline,param_distributions=param_grid, n_iter=10,scoring='neg_mean_squared_error', cv=4)\r\n",
    "rand_search.fit(X,y)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'ABCMeta' object is not subscriptable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18212/2978693146.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'st_scaler'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'xgb_model'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m param_grid={\n\u001b[0;32m      5\u001b[0m     \u001b[1;34m'xgb_model__subsample'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ABCMeta' object is not subscriptable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Project 3 (FAILED)\r\n",
    "\r\n",
    " The chronic kidney disease dataset contains both categorical and numeric features, but contains lots of missing values. The goal here is to predict who has chronic kidney disease given various blood indicators as features."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "df=pd.read_csv('kidney_disease.csv')\r\n",
    "df['rc']= pd.to_numeric(df['rc'], errors='coerce')\r\n",
    "df['pcv']= pd.to_numeric(df['pcv'], errors='coerce')\r\n",
    "df['wc']= pd.to_numeric(df['wc'], errors='coerce')\r\n",
    "\r\n",
    "\r\n",
    "y=df['classification']\r\n",
    "X=df.drop(columns=['classification'])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def extract_cat_num(df):\r\n",
    "    cat_col=[col for col in df.columns if df[col].dtype=='object']\r\n",
    "    num_col=[col for col in df.columns if df[col].dtype!='object']\r\n",
    "    return cat_col,num_col\r\n",
    "\r\n",
    "cat_col,num_col=extract_cat_num(df)\r\n",
    "for col in cat_col:\r\n",
    "    print('{} has {} values '.format(col,df[col].unique()))\r\n",
    "    print('\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "rbc has [nan 'normal' 'abnormal'] values \n",
      "\n",
      "\n",
      "pc has ['normal' 'abnormal' nan] values \n",
      "\n",
      "\n",
      "pcc has ['notpresent' 'present' nan] values \n",
      "\n",
      "\n",
      "ba has ['notpresent' 'present' nan] values \n",
      "\n",
      "\n",
      "htn has ['yes' 'no' nan] values \n",
      "\n",
      "\n",
      "dm has ['yes' 'no' ' yes' '\\tno' '\\tyes' nan] values \n",
      "\n",
      "\n",
      "cad has ['no' 'yes' '\\tno' nan] values \n",
      "\n",
      "\n",
      "appet has ['good' 'poor' nan] values \n",
      "\n",
      "\n",
      "pe has ['no' 'yes' nan] values \n",
      "\n",
      "\n",
      "ane has ['no' 'yes' nan] values \n",
      "\n",
      "\n",
      "classification has ['ckd' 'ckd\\t' 'notckd'] values \n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Import necessary modules\r\n",
    "from sklearn_pandas import DataFrameMapper\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "\r\n",
    "# Check number of nulls in each feature column\r\n",
    "nulls_per_column = X.isnull().sum()\r\n",
    "print(nulls_per_column)\r\n",
    "\r\n",
    "# Create a boolean mask for categorical columns\r\n",
    "categorical_feature_mask = X.dtypes == object\r\n",
    "\r\n",
    "# Get list of categorical column names\r\n",
    "categorical_columns = X.columns[categorical_feature_mask].tolist()\r\n",
    "\r\n",
    "# Get list of non-categorical column names\r\n",
    "non_categorical_columns = X.columns[~categorical_feature_mask].tolist()\r\n",
    "\r\n",
    "for col in categorical_columns:\r\n",
    "    print('{} has {} values '.format(col,df[col].unique()))\r\n",
    "    print('\\n')\r\n",
    "\r\n",
    "\r\n",
    "# Apply numeric imputer\r\n",
    "numeric_imputation_mapper = DataFrameMapper(\r\n",
    "                                            [([numeric_feature],SimpleImputer(strategy=\"median\")) for numeric_feature in non_categorical_columns],\r\n",
    "                                            input_df=True,\r\n",
    "                                            df_out=True\r\n",
    "                                           )\r\n",
    "\r\n",
    "# Apply categorical imputer\r\n",
    "categorical_imputation_mapper = DataFrameMapper(\r\n",
    "                                                [(category_feature, SimpleImputer()) for category_feature in categorical_columns],\r\n",
    "                                                input_df=True,\r\n",
    "                                                df_out=True\r\n",
    "                                               )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "id         0\n",
      "age        9\n",
      "bp        12\n",
      "sg        47\n",
      "al        46\n",
      "su        49\n",
      "rbc      152\n",
      "pc        65\n",
      "pcc        4\n",
      "ba         4\n",
      "bgr       44\n",
      "bu        19\n",
      "sc        17\n",
      "sod       87\n",
      "pot       88\n",
      "hemo      52\n",
      "pcv       71\n",
      "wc       106\n",
      "rc       131\n",
      "htn        2\n",
      "dm         2\n",
      "cad        2\n",
      "appet      1\n",
      "pe         1\n",
      "ane        1\n",
      "dtype: int64\n",
      "rbc has [nan 'normal' 'abnormal'] values \n",
      "\n",
      "\n",
      "pc has ['normal' 'abnormal' nan] values \n",
      "\n",
      "\n",
      "pcc has ['notpresent' 'present' nan] values \n",
      "\n",
      "\n",
      "ba has ['notpresent' 'present' nan] values \n",
      "\n",
      "\n",
      "htn has ['yes' 'no' nan] values \n",
      "\n",
      "\n",
      "dm has ['yes' 'no' ' yes' '\\tno' '\\tyes' nan] values \n",
      "\n",
      "\n",
      "cad has ['no' 'yes' '\\tno' nan] values \n",
      "\n",
      "\n",
      "appet has ['good' 'poor' nan] values \n",
      "\n",
      "\n",
      "pe has ['no' 'yes' nan] values \n",
      "\n",
      "\n",
      "ane has ['no' 'yes' nan] values \n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Having separately imputed numeric as well as categorical columns, your task is now to use scikit-learn's FeatureUnion to concatenate their results, which are contained in two separate transformer objects - numeric_imputation_mapper, and categorical_imputation_mapper, respectively."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Import FeatureUnion\r\n",
    "from sklearn.pipeline import FeatureUnion\r\n",
    "\r\n",
    "# Combine the numeric and categorical transformations\r\n",
    "numeric_categorical_union = FeatureUnion([\r\n",
    "                                          (\"num_mapper\", numeric_imputation_mapper),\r\n",
    "                                          (\"cat_mapper\", categorical_imputation_mapper)\r\n",
    "                                         ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PROBLEMA CON EL PIPELINEEEEEEEEEEEE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's time to piece together all of the transforms along with an XGBClassifier to build the full pipeline!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Create full pipeline\r\n",
    "pipeline = Pipeline([\r\n",
    "                     (\"featureunion\", numeric_categorical_union),\r\n",
    "                     #(\"dictifier\", Dictifier()),\r\n",
    "                     (\"vectorizer\", DictVectorizer(sort=False)),\r\n",
    "                     (\"clf\", xgb.XGBClassifier(max_depth=3))\r\n",
    "                    ])\r\n",
    "\r\n",
    "# Perform cross-validation\r\n",
    "cross_val_scores = cross_val_score(pipeline, df, y, scoring=\"roc_auc\", cv=3)\r\n",
    "\r\n",
    "# Print avg. AUC\r\n",
    "print(\"3-fold AUC: \", np.mean(cross_val_scores))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3-fold AUC:  nan\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 303, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 980, in fit_transform\n",
      "    results = self._parallel_func(X, y, fit_params, _fit_transform_one)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 1002, in _parallel_func\n",
      "    return Parallel(n_jobs=self.n_jobs)(delayed(func)(\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1044, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py\", line 443, in fit_transform\n",
      "    return self._transform(X, y, True)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py\", line 342, in _transform\n",
      "    Xt = _call_fit(transformers.fit_transform, Xt, y)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn_pandas\\pipeline.py\", line 24, in _call_fit\n",
      "    return fit_method(X, y, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\impute\\_base.py\", line 288, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\impute\\_base.py\", line 260, in _validate_input\n",
      "    raise new_ve from None\n",
      "ValueError: rbc: Cannot use mean strategy with non-numeric data:\n",
      "could not convert string to float: 'normal'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 303, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 980, in fit_transform\n",
      "    results = self._parallel_func(X, y, fit_params, _fit_transform_one)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 1002, in _parallel_func\n",
      "    return Parallel(n_jobs=self.n_jobs)(delayed(func)(\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1044, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py\", line 443, in fit_transform\n",
      "    return self._transform(X, y, True)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py\", line 342, in _transform\n",
      "    Xt = _call_fit(transformers.fit_transform, Xt, y)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn_pandas\\pipeline.py\", line 24, in _call_fit\n",
      "    return fit_method(X, y, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\impute\\_base.py\", line 288, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\impute\\_base.py\", line 260, in _validate_input\n",
      "    raise new_ve from None\n",
      "ValueError: rbc: Cannot use mean strategy with non-numeric data:\n",
      "could not convert string to float: 'normal'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 303, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 980, in fit_transform\n",
      "    results = self._parallel_func(X, y, fit_params, _fit_transform_one)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 1002, in _parallel_func\n",
      "    return Parallel(n_jobs=self.n_jobs)(delayed(func)(\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1044, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py\", line 443, in fit_transform\n",
      "    return self._transform(X, y, True)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py\", line 342, in _transform\n",
      "    Xt = _call_fit(transformers.fit_transform, Xt, y)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn_pandas\\pipeline.py\", line 24, in _call_fit\n",
      "    return fit_method(X, y, **kwargs)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\impute\\_base.py\", line 288, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "  File \"C:\\Users\\56945\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\impute\\_base.py\", line 260, in _validate_input\n",
      "    raise new_ve from None\n",
      "ValueError: rbc: Cannot use mean strategy with non-numeric data:\n",
      "could not convert string to float: 'normal'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "eb10dc7af34d8b2d8e4e13c255a62d72cda2839118676834d127e6a78e1763b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}