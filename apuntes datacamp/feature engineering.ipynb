{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SurveyDate                                    FormalEducation  \\\n",
      "0  2/28/18 20:20           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
      "1  6/28/18 13:26           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
      "2    6/6/18 3:37           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
      "3    5/9/18 1:06  Some college/university study without earning ...   \n",
      "4  4/12/18 22:41           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
      "\n",
      "   ConvertedSalary Hobby       Country  StackOverflowJobsRecommend  \\\n",
      "0              NaN   Yes  South Africa                         NaN   \n",
      "1          70841.0   Yes       Sweeden                         7.0   \n",
      "2              NaN    No       Sweeden                         8.0   \n",
      "3          21426.0   Yes       Sweeden                         NaN   \n",
      "4          41671.0   Yes            UK                         8.0   \n",
      "\n",
      "      VersionControl  Age  Years Experience Gender   RawSalary  \n",
      "0                Git   21                13   Male         NaN  \n",
      "1     Git;Subversion   38                 9   Male   70,841.00  \n",
      "2                Git   45                11    NaN         NaN  \n",
      "3  Zip file back-ups   46                12   Male   21,426.00  \n",
      "4                Git   39                 7   Male  £41,671.00  \n",
      "---------------------------------------------------------\n",
      "SurveyDate                     object\n",
      "FormalEducation                object\n",
      "ConvertedSalary               float64\n",
      "Hobby                          object\n",
      "Country                        object\n",
      "StackOverflowJobsRecommend    float64\n",
      "VersionControl                 object\n",
      "Age                             int64\n",
      "Years Experience                int64\n",
      "Gender                         object\n",
      "RawSalary                      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "so_survey_df=pd.read_csv(r'G:\\Mi unidad\\Universidad\\Uni\\Data science\\Heavy Datasets\\stackoverflow_Data.csv')\n",
    "\n",
    "print(so_survey_df.head())\n",
    "print('---------------------------------------------------------')\n",
    "print(so_survey_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ConvertedSalary', 'StackOverflowJobsRecommend', 'Age',\n",
      "       'Years Experience'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create subset of only the numeric columns\n",
    "so_numeric_df = so_survey_df.select_dtypes(include=['int','float'])\n",
    "\n",
    "print(so_numeric_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with categorical variables\n",
    "* One-hot encoding\n",
    "* get_dummies(df,columns=[],prefix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SurveyDate', 'FormalEducation', 'ConvertedSalary', 'Hobby',\n",
      "       'StackOverflowJobsRecommend', 'VersionControl', 'Age',\n",
      "       'Years Experience', 'Gender', 'RawSalary', 'OH_France', 'OH_India',\n",
      "       'OH_Ireland', 'OH_Russia', 'OH_South Africa', 'OH_Spain', 'OH_Sweeden',\n",
      "       'OH_UK', 'OH_USA', 'OH_Ukraine'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convert the Country column to a one hot encoded Data Frame\n",
    "one_hot_encoded = pd.get_dummies(so_survey_df, columns=['Country'], prefix='OH')\n",
    "\n",
    "# Print the columns names\n",
    "print(one_hot_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SurveyDate', 'FormalEducation', 'ConvertedSalary', 'Hobby',\n",
      "       'StackOverflowJobsRecommend', 'VersionControl', 'Age',\n",
      "       'Years Experience', 'Gender', 'RawSalary', 'DM_India', 'DM_Ireland',\n",
      "       'DM_Russia', 'DM_South Africa', 'DM_Spain', 'DM_Sweeden', 'DM_UK',\n",
      "       'DM_USA', 'DM_Ukraine'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create dummy variables for the Country column\n",
    "dummy = pd.get_dummies(so_survey_df, columns=['Country'], drop_first=True, prefix='DM')\n",
    "\n",
    "# Print the columns names\n",
    "print(dummy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia entre ambas es que dummy variables elimina el primer valor dejando una columna menos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "siguiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos una mask para poder reemplazar los valores que menos se repiten a lo largo del dataset y así agruparlos en otra categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South Africa    166\n",
      "USA             164\n",
      "Spain           134\n",
      "Sweeden         119\n",
      "France          115\n",
      "Russia           97\n",
      "UK               95\n",
      "India            95\n",
      "Other            14\n",
      "Name: Country, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\56945\\AppData\\Local\\Temp/ipykernel_22772/1238127852.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  countries[mask] = 'Other'\n"
     ]
    }
   ],
   "source": [
    "# Create a series out of the Country column\n",
    "countries = so_survey_df['Country']\n",
    "\n",
    "# Get the counts of each category\n",
    "country_counts = countries.value_counts()\n",
    "\n",
    "# Create a mask for only categories that occur less than 10 times\n",
    "mask = countries.isin(country_counts[country_counts < 10].index)\n",
    "\n",
    "# Label all other categories as Other\n",
    "countries[mask] = 'Other'\n",
    "\n",
    "# Print the updated category counts\n",
    "print(countries.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Paid_Job  ConvertedSalary\n",
      "0         0              0.0\n",
      "1         1          70841.0\n",
      "2         0              0.0\n",
      "3         1          21426.0\n",
      "4         1          41671.0\n"
     ]
    }
   ],
   "source": [
    "so_survey_df.ConvertedSalary.fillna(value=0,inplace=True)\n",
    "\n",
    "# Create the Paid_Job column filled with zeros\n",
    "so_survey_df['Paid_Job'] = 0\n",
    "\n",
    "# Replace all the Paid_Job values where ConvertedSalary is > 0\n",
    "so_survey_df.loc[so_survey_df['ConvertedSalary']>0, 'Paid_Job'] = 1\n",
    "\n",
    "# Print the first five rows of the columns\n",
    "print(so_survey_df[['Paid_Job', 'ConvertedSalary']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          equal_binned  ConvertedSalary\n",
      "0  (-2000.0, 400000.0]              0.0\n",
      "1  (-2000.0, 400000.0]          70841.0\n",
      "2  (-2000.0, 400000.0]              0.0\n",
      "3  (-2000.0, 400000.0]          21426.0\n",
      "4  (-2000.0, 400000.0]          41671.0\n",
      "------------defining limits--------------- \n",
      "  boundary_binned  ConvertedSalary\n",
      "0        Very low              0.0\n",
      "1          Medium          70841.0\n",
      "2        Very low              0.0\n",
      "3             Low          21426.0\n",
      "4             Low          41671.0\n"
     ]
    }
   ],
   "source": [
    "# Bin the continuous variable ConvertedSalary into 5 bins\n",
    "so_survey_df['equal_binned'] = pd.cut(so_survey_df['ConvertedSalary'], bins=5)\n",
    "\n",
    "# Print the first 5 rows of the equal_binned column\n",
    "print(so_survey_df[['equal_binned', 'ConvertedSalary']].head())\n",
    "\n",
    "\n",
    "print('------------defining limits--------------- ')\n",
    "# Specify the boundaries of the bins\n",
    "bins = [-np.inf, 10000, 50000, 100000, 150000, np.inf]\n",
    "\n",
    "# Bin labels\n",
    "labels = ['Very low', 'Low', 'Medium', 'High', 'Very high']\n",
    "\n",
    "# Bin the continuous variable ConvertedSalary using these boundaries\n",
    "so_survey_df['boundary_binned'] = pd.cut(so_survey_df['ConvertedSalary'], \n",
    "                                         bins=bins, labels=labels)\n",
    "\n",
    "# Print the first 5 rows of the boundary_binned column\n",
    "print(so_survey_df[['boundary_binned', 'ConvertedSalary']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing and null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age       999\n",
      "Gender    693\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Subset the DataFrame\n",
    "sub_df = so_survey_df[['Age','Gender']]\n",
    "# Print the number of non-missing values\n",
    "print(sub_df.notnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 14)\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame dropping all incomplete0'any rows\n",
    "no_missing_values_rows = so_survey_df.dropna(how='any')\n",
    "\n",
    "# Print the shape of the new DataFrame\n",
    "print(no_missing_values_rows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 11)\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame dropping all columns with incomplete rows\n",
    "no_missing_values_cols = so_survey_df.dropna(how='any', axis=1)\n",
    "\n",
    "# Print the shape of the new DataFrame\n",
    "print(no_missing_values_cols.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693, 14)\n"
     ]
    }
   ],
   "source": [
    "# Drop all rows where Gender is missing\n",
    "no_gender = so_survey_df.dropna(subset=['Gender'])\n",
    "\n",
    "# Print the shape of the new DataFrame\n",
    "print(no_gender.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    7.0\n",
      "2    8.0\n",
      "3    NaN\n",
      "4    8.0\n",
      "Name: StackOverflowJobsRecommend, dtype: float64\n",
      "-----------------------------------------\n",
      "0    7.0\n",
      "1    7.0\n",
      "2    8.0\n",
      "3    7.0\n",
      "4    8.0\n",
      "Name: StackOverflowJobsRecommend, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(so_survey_df['StackOverflowJobsRecommend'].head())\n",
    "\n",
    "print('-----------------------------------------')\n",
    "# Fill missing values with the mean\n",
    "so_survey_df['StackOverflowJobsRecommend'].fillna(so_survey_df['StackOverflowJobsRecommend'].median(), inplace=True)\n",
    "\n",
    "# Round the StackOverflowJobsRecommend values\n",
    "so_survey_df['StackOverflowJobsRecommend'] = round(so_survey_df['StackOverflowJobsRecommend'])\n",
    "\n",
    "# Print the top 5 rows\n",
    "print(so_survey_df['StackOverflowJobsRecommend'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When working with predictive models you will often have a separate train and test DataFrames. In these cases you want to ensure no information from your test set leaks into your train set. When filling missing values in data to be used in these situations how should approach the two data sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the measures of central tendency (mean/median etc.) calculated on the train set to both the train and test sets."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb10dc7af34d8b2d8e4e13c255a62d72cda2839118676834d127e6a78e1763b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
